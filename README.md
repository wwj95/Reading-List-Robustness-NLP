
# Reading list

### 1. Survey paper
1. Towards a Robust Deep Neural Network in Texts: A Survey. Wenqi Wang, Lina Wang, Benxiao Tang, Run Wang, Aoshuang Ye. arXiv 2020. [pdf](https://arxiv.org/pdf/1902.07285.pdf)
2. Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey. Wei Emma Zhang, Quan Z. Sheng, Ahoud Alhazmi, Chenliang Li. ACM TIST 2020.[pdf](https://dl.acm.org/doi/abs/10.1145/3374217)
### 2. Attack Paper
#### 1) Word-Level attack
1. Word-level Textual Adversarial Attacking as Combinatorial Optimization. Yuan Zang, Fanchao Qi, Chenghao Yang, Zhiyuan Liu, Meng Zhang, Qun Liu, Maosong Sun. ACL 2020. [pdf](https://arxiv.org/pdf/1910.12196.pdf)
2. It's Morphin' Time! Combating Linguistic Discrimination with Inflectional Perturbations. Samson Tan, Shafiq Joty, Min-Yen Kan, Richard Socher. ACL 2020. [pdf](https://www.aclweb.org/anthology/2020.acl-main.263.pdf)
3. On the Robustness of Language Encoders against Grammatical Errors. Fan Yin, Quanyu Long, Tao Meng, Kai-Wei Chang. ACL 2020. [pdf](https://www.aclweb.org/anthology/2020.acl-main.310.pdf)
4. Evaluating and Enhancing the Robustness of Neural Network-based Dependency Parsing Models with Adversarial Examples. Xiaoqing Zheng, Jiehang Zeng, Yi Zhou, Cho-Jui Hsieh, Minhao Cheng, Xuanjing Huang. ACL 2020.[pdf](https://www.aclweb.org/anthology/2020.acl-main.590.pdf)
5. A Reinforced Generation of Adversarial Examples for Neural Machine Translation. Wei Zou, Shujian Huang, Jun Xie, Xinyu Dai, Jiajun Chen. ACL 2020.[pdf](https://www.aclweb.org/anthology/2020.acl-main.319.pdf)
6. Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment. Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits. AAAI 2020.[pdf](https://arxiv.org/pdf/1907.11932v4.pdf)
7. Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples. Minhao Cheng, Jinfeng Yi, Pin-Yu Chen, Huan Zhang, Cho-Jui Hsieh. AAAI 2020.[pdf](https://arxiv.org/pdf/1803.01128.pdf)
8. Generating Natural Language Adversarial Examples through Probability Weighted Word Saliency. Shuhuai Ren, Yihe Deng, Kun He, Wanxiang Che. ACL 2019.[pdf](https://www.aclweb.org/anthology/P19-1103.pdf)
9. Generating Natural Language Adversarial Examples. Moustafa Alzantot, Yash Sharma, Ahmed Elgohary, Bo-Jhang Ho, Mani Srivastava, Kai-Wei Chang. EMNLP 2018.[pdf](https://www.aclweb.org/anthology/D18-1316/)

#### 2) Character-level attack
1. Text Processing Like Humans Do: Visually Attacking and Shielding NLP Systems. Steffen Eger, Gözde Gül ¸Sahin, Andreas Rücklé, Ji-Ung Lee, Claudia Schulz, Mohsen Mesgar, Krishnkant Swarnkar, Edwin Simpson, Iryna Gurevych. NAACL-HLT 2019.[pdf](https://www.aclweb.org/anthology/N19-1165/)
2. Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers. Ji Gao, Jack Lanchantin, Mary Lou Soffa, Yanjun Qi. IEEE SPW 2018. [pdf](https://ieeexplore.ieee.org/document/8424632)

#### 3) Sentence-level attack
1. Adversarial Texts with Gradient Methods. Zhitao Gong, Wenlu Wang, Bo Li, Dawn Song, Wei-Shinn Ku. arXiv 2018 [pdf](https://arxiv.org/abs/1801.07175)
2. Interpretable Adversarial Perturbation in Input Embedding Space for Text. Motoki Sato, Jun Suzuki, Hiroyuki Shindo, Yuji Matsumoto. ijcai 2018. [pdf](https://arxiv.org/abs/1805.02917)

### 3. Defense Paper
1. Robust Encodings: A Framework for Combating Adversarial Typos. Erik Jones, Robin Jia, Aditi Raghunathan, Percy Liang. ACL 2020 [pdf](https://www.aclweb.org/anthology/2020.acl-main.245.pdf)
2. Joint Character-level Word Embedding and Adversarial Stability Training to Defend Adversarial Text. Hui Liu, Yongzheng Zhang, Yipeng Wang, Zheng Lin, Yige Chen. AAAI 2020
3. Combating Adversarial Misspellings with Robust Word Recognition. Danish Pruthi, Bhuwan Dhingra, Zachary C. Lipton. ACL 2019. [pdf](https://www.aclweb.org/anthology/P19-1561.pdf)

### Certified Robustness
1. Certified Robustness to Adversarial Word Substitutions. Robin Jia, Aditi Raghunathan, Kerem Göksel, Percy Liang. EMNLP-IJCNLP 2019.[pdf](https://www.aclweb.org/anthology/D19-1423.pdf)
2. Achieving Verified Robustness to Symbol Substitutions via Interval Bound Propagation. Po-Sen Huang, Robert Stanforth, Johannes Welbl, Chris Dyer, Dani Yogatama, Sven Gowal, Krishnamurthy Dvijotham, Pushmeet Kohli. EMNLP-IJCNLP 2019.[pdf](https://www.aclweb.org/anthology/D19-1419.pdf)
3. Robustness Verification for Transformers. Zhouxing Shi, Huan Zhang, Kai-Wei Chang, Minlie Huang, Cho-Jui Hsieh. ICLR 2020. [pdf](https://arxiv.org/pdf/2002.06622.pdf)
4. SAFER: A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions. [pdf](https://www.aclweb.org/anthology/2020.acl-main.317.pdf)
